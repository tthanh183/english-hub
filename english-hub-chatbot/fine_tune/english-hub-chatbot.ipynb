{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":11964218,"sourceType":"datasetVersion","datasetId":7523181},{"sourceId":12253998,"sourceType":"datasetVersion","datasetId":7721241}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\ntorch.cuda.empty_cache()\ntorch.cuda.memory_allocated()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install transformers datasets accelerate -q","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nimport json\nimport torch\nfrom datasets import Dataset\nfrom transformers import T5Tokenizer, T5ForConditionalGeneration, TrainingArguments, Trainer","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_name = \"google/flan-t5-base\"\ntokenizer = T5Tokenizer.from_pretrained(model_name)\nmodel = T5ForConditionalGeneration.from_pretrained(model_name).to(\"cuda\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = pd.read_csv(\"/kaggle/input/words-cam/output.csv\") \n\ndefinition_templates = [\n    \"What does {word} mean?\",\n    \"Can you define {word}?\",\n    \"Tell me the meaning of {word}.\",\n    \"What's the meaning of {word}?\",\n    \"Explain the word {word}.\"\n]\nexample_templates = [\n    \"Can you give me an example of {word}?\",\n    \"Show me a sentence using {word}.\",\n    \"How is {word} used in a sentence?\",\n    \"Give an example sentence with {word}.\",\n    \"Use {word} in a sentence.\"\n]\n\ndata_vocab = []\nfor _, row in df.iterrows():\n    word = str(row[\"word\"])\n    definition = str(row[\"definition\"]) if pd.notnull(row[\"definition\"]) else \"No definition available.\"\n    example = str(row[\"example\"]) if pd.notnull(row[\"example\"]) else \"No example available.\"\n\n    for temp in definition_templates:\n        instruction = temp.format(word=word)\n        response = definition\n        data_vocab.append({\"instruction\": instruction, \"response\": response})\n\n    for temp in example_templates:\n        instruction = temp.format(word=word)\n        response = example\n        data_vocab.append({\"instruction\": instruction, \"response\": response})\n\n# 3. Đọc dữ liệu ngoài (out-domain)\nout_domain_file = \"/kaggle/input/ood-json/ood_data.jsonl\"  \ndata_out_domain = []\nwith open(out_domain_file, \"r\") as f:\n    for line in f:\n        item = json.loads(line)\n        data_out_domain.append(item)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"greeting_templates = [\n    \"Hi, how are you?\", \"Hello, nice to meet you.\", \"Good morning!\", \"Hey there!\", \"Hi\", \"Hello\"\n]\nfarewell_templates = [\n    \"Goodbye!\", \"Bye\", \"See you later!\", \"Have a nice day!\", \"Take care!\"\n]\nintro_templates = [\n    \"Tell me about yourself.\", \"Who are you?\", \"Introduce yourself.\"\n]\n\nfor temp in greeting_templates:\n    data_vocab.append({\"instruction\": temp, \"response\": \"Hello! How can I assist you today?\"})\n\nfor temp in farewell_templates:\n    data_vocab.append({\"instruction\": temp, \"response\": \"Goodbye! Have a great day!\"})\n\nfor temp in intro_templates:\n    data_vocab.append({\"instruction\": temp, \"response\": \"I'm a language model trained to assist you with various tasks!\"})","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data_all = data_vocab + data_out_domain\ndataset = Dataset.from_pandas(pd.DataFrame(data_all).reset_index(drop=True))\n\nprint(\"Number of samples in data_vocab:\", len(data_vocab))\nprint(\"Number of samples in data_out_domain:\", len(data_out_domain))\nprint(\"Total number of samples after merging:\", len(data_all))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"max_length = 256\n\ndef preprocess(example):\n    input_text = example['instruction']\n    target_text = example['response']\n    model_inputs = tokenizer(input_text, max_length=max_length, truncation=True, padding=\"max_length\")\n    labels = tokenizer(target_text, max_length=max_length, truncation=True, padding=\"max_length\")\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_dataset = dataset.map(preprocess)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir=\"./flan-t5-finetuned-vocab\",\n    per_device_train_batch_size=8,  \n    num_train_epochs=3,  \n    learning_rate=3e-5,\n    fp16=True,\n    save_strategy=\"epoch\",\n    logging_strategy=\"steps\",\n    logging_steps=50,\n    report_to=\"none\"\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=tokenized_dataset,\n    tokenizer=tokenizer\n)\n\ntrainer.train()\n\nmodel.save_pretrained(\"./flan-t5-finetuned-vocab\")\ntokenizer.save_pretrained(\"./flan-t5-finetuned-vocab\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model_path = \"./flan-t5-finetuned-vocab\"\nmodel = T5ForConditionalGeneration.from_pretrained(model_path).to(\"cuda\")\ntokenizer = T5Tokenizer.from_pretrained(model_path)\n\ndef ask_model(prompt):\n    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True).to(\"cuda\")\n    outputs = model.generate(**inputs, max_new_tokens=100)\n    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n\nask_model(\"Hello\")\nask_model(\"Define the meaning of embassy\")\nask_model(\"Give me an example sentence using embassy\")\nask_model(\"What is the weather like today\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}